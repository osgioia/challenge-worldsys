
# üìÑ Procesamiento de Archivos Grandes y Volcado a Base de Datos

## üöÄ Instalaci√≥n y uso

Este servicio est√° preparado para ser ejecutado mediante Docker. Sigue estos pasos:

### 1. Levantar el servicio

```bash
docker compose up -d
```

### 2. Cargar archivos para procesamiento

Los archivos `.dat` deben colocarse en el volumen del contenedor en la carpeta `/uploads/process`. Pod√©s subirlos as√≠:

```bash
docker cp archivo.dat nombre_del_contenedor:/uploads/process
```

> üìÅ Asegurate de que el archivo tenga el formato esperado (pipe-separated y validado con Joi).

---

## üì° Endpoints disponibles

| Endpoint       | Descripci√≥n                                |
|----------------|--------------------------------------------|
| `/health`      | Devuelve el estado del servicio.           |
| `/metrics`     | Expone m√©tricas para Prometheus.           |
| `/api-docs`    | Documentaci√≥n Swagger (OpenAPI).           |

Las m√©tricas incluyen:
- Uso de memoria (`nodejs_process_memory_rss_bytes`)
- Uso de CPU (`nodejs_process_cpu_percent`)
- M√©tricas est√°ndar de Node.js

---

## 1. Lectura eficiente de archivos grandes

Para respetar los l√≠mites impuestos por el challenge y procesar archivos `.dat` de gran tama√±o, se implement√≥ la lectura mediante **streams**, lo cual permite:

- Leer el archivo l√≠nea por l√≠nea o en bloques.
- Procesar archivos de cualquier tama√±o sin consumir toda la RAM.

> ‚ö†Ô∏è En ning√∫n momento se vuelca el contenido completo del archivo (ni siquiera en chunks grandes) a memoria. Esto evita que el servicio se bloquee o que Kubernetes reinicie el pod por exceso de uso de recursos.

---

## 2. Inserci√≥n optimizada en base de datos

El proceso de escritura se realiza por lotes (`chunks`) y con m√∫ltiples capas de optimizaci√≥n:

- ‚úÖ **Agrupamiento en chunks:** los registros se agrupan en bloques de tama√±o configurable para evitar inserciones individuales.
- üöÄ **Bulk insert v√≠a stored procedure:** la l√≥gica de transacci√≥n se delega a SQL Server mediante un `stored procedure`, reduciendo la carga sobre el servicio.
- üõ†Ô∏è **Manejo de errores:** si un chunk falla, se registra el error sin detener el procesamiento del resto del archivo.

---

## 3. Razonamiento detr√°s de las optimizaciones

Cada t√©cnica responde a un cuello de botella distinto:

| T√©cnica               | Problema que resuelve                                                        |
|-----------------------|-----------------------------------------------------------------------------|
| **Streams**           | Evitan el consumo excesivo de memoria.                                     |
| **Batching**          | Permite procesar registros de forma escalonada, sin acumulaci√≥n infinita.  |
| **Bulk insert**       | Mejora la velocidad de escritura de grandes vol√∫menes.                     |
| **Manejo de errores** | Robustez ante datos corruptos (validaci√≥n con Joi de l√≠neas separadas por `|`). |
| **Pool de conexiones**| Permite escalar horizontalmente y soportar m√∫ltiples hilos o workers.       |
| **Watcher**           | Mueve los archivos por diferentes carpetas para evitar que se procesen m√∫ltiples veces. |
| **Prometheus**        | Se utiliza para exponer m√©tricas del proceso y monitorear el rendimiento del servicio en tiempo real. |

---

## 4. Flujo de procesamiento

```text
Archivo .dat grande ‚Üí /uploads/process
         ‚Üì
Lectura del archivo por streams ‚Üí /uploads/processing
         ‚Üì
Buffer de registros (batch/chunks)
         ‚Üì
Inserci√≥n en base de datos
‚Üí Bulk insert + transacci√≥n (stored procedure)
         ‚Üì
Validaci√≥n (Joi) + Logs (Winston)
         ‚Üì
Exposici√≥n de m√©tricas (Prometheus)
```

---

## 5. Justificaci√≥n de la arquitectura

Se combinan distintas t√©cnicas por motivos de rendimiento, escalabilidad y robustez:

- Leer con streams pero insertar de a uno generar√≠a cuellos de botella y puede volverse bloqueante si no se libera correctamente la memoria.
- Leer el archivo completo no es opci√≥n: agotar√≠a la RAM y Kubernetes reiniciar√≠a el pod.
- Usar `stored procedures` delega la l√≥gica transaccional en SQL Server, lo que mejora la eficiencia y evita problemas de concurrencia o locks a nivel de aplicaci√≥n.
- Las **m√©tricas expuestas con Prometheus** permiten medir en tiempo real el estado del procesamiento, duraci√≥n de cada batch, cantidad de errores, tama√±o de archivos procesados, entre otros indicadores clave.

---

## 6. Posibles mejoras

Algunas ideas para futuras versiones del sistema:

- ‚òÅÔ∏è **Almacenamiento en S3:** en lugar de mover archivos por carpetas locales, se podr√≠an almacenar en un bucket S3. Los pods podr√≠an observar el bucket y usar `.lock` o metadata para evitar colisiones.
- üîÑ **Sistemas de mensajer√≠a (Kafka, RabbitMQ):** los datos podr√≠an ser enviados por eventos o colas para desacoplar el procesamiento.
- üìà **Mejoras en infraestructura:** aumentar la RAM por pod permitir√≠a trabajar con chunks m√°s grandes. Actualmente, un archivo de 4‚ÄØGB puede tardar cerca de 3 horas en procesarse. Con 20‚ÄØGB, el rendimiento cae a√∫n m√°s.

---

## üõ†Ô∏è Tecnolog√≠as utilizadas

- **Node.js**
- **TypeScript**
- **SQL Server**
- **Joi** (validaci√≥n de datos)
- **Winston** (logger)
- **Streams**
- **Stored Procedures**
- **Docker / Kubernetes-ready**
- **Prometheus** (exposici√≥n de m√©tricas para monitoreo)
- **Swagger / OpenAPI**

## Configuraci√≥n de Kubernetes 

Para ejecutar el servicio en Kubernetes, usa el archivo kubernetes-deployment.yml con el siguiente comando:

```bash
kubectl apply -f kubernetes-deployment.yml
```

Este archivo incluye el Deployment, PersistentVolumeClaim, Service y el HorizontalPodAutoscaler necesarios para el correcto funcionamiento del servicio en el cl√∫ster de Kubernetes.